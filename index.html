<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>DocScanner Pro</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script async src="https://docs.opencv.org/4.5.4/opencv.js" onload="onOpenCvLoaded();"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.5.1/jspdf.umd.min.js"></script>
</head>
<body class="bg-slate-900 text-white font-sans overflow-x-hidden">

    <div class="max-w-lg mx-auto p-4 flex flex-col min-h-screen">
        <header class="py-4 flex justify-between items-center">
            <h1 class="text-2xl font-black text-green-500 italic">DocScanner</h1>
            <div class="flex gap-2 items-center">
                <button id="torchBtn" onclick="toggleTorch()" class="hidden bg-slate-800 p-2 rounded-lg border border-slate-700">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 text-yellow-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z" /></svg>
                </button>
                <span id="status" class="text-[10px] bg-yellow-600 px-2 py-1 rounded font-bold uppercase tracking-tighter">Initialisation...</span>
            </div>
        </header>

        <div class="relative w-full aspect-[3/4] bg-black rounded-3xl overflow-hidden border-2 border-slate-700 shadow-2xl">
            <video id="videoInput" class="absolute inset-0 w-full h-full object-cover" autoplay playsinline muted></video>
            <canvas id="canvasOutput" class="absolute inset-0 w-full h-full z-10 pointer-events-none"></canvas>
            <div id="aiOverlay" class="absolute top-4 left-4 z-20 bg-black/60 px-3 py-1 rounded-full text-[10px] font-bold text-green-400 border border-green-500/50">FLUX EN ATTENTE...</div>
        </div>

        <div class="mt-6 space-y-4">
            <input type="text" id="docFileName" placeholder="Nom du document (Optionnel)" class="w-full bg-slate-800 border-none p-4 rounded-2xl text-white outline-none focus:ring-2 focus:ring-green-500">
            <button onclick="captureAndWarp()" id="captureBtn" class="w-full bg-green-600 py-5 rounded-2xl font-black text-lg active:scale-95 transition-all shadow-lg">
                SCANNER LE DOCUMENT
            </button>
        </div>

        <div id="storageHistory" class="mt-8 space-y-2 pb-10"></div>
    </div>

    <canvas id="warpCanvas" style="display:none;"></canvas>

    <script>
        const { jsPDF } = window.jspdf;
        let video = document.getElementById('videoInput');
        let src, dst, cap, streamRef;
        let lastBestApprox = null;
        let torchOn = false;
        let isEngineRunning = false;

        // 1. Démarrage Caméra Immédiat
        async function initCamera() {
            try {
                streamRef = await navigator.mediaDevices.getUserMedia({ 
                    video: { facingMode: "environment", width: { ideal: 1280 } }, 
                    audio: false 
                });
                video.srcObject = streamRef;
                // Force la lecture pour certains navigateurs mobiles
                await video.play();
                checkReady();
            } catch (err) {
                document.getElementById('aiOverlay').innerText = "ERREUR ACCÈS CAMÉRA";
            }
        }

        // 2. Callback OpenCV
        function onOpenCvLoaded() {
            cv.onRuntimeInitialized = () => {
                document.getElementById('status').innerText = "VISION PRÊTE";
                document.getElementById('status').className = "text-[10px] bg-green-600 px-2 py-1 rounded font-bold uppercase";
                checkReady();
            };
        }

        // 3. Vérification de démarrage
        function checkReady() {
            if (typeof cv !== 'undefined' && cv.Mat && video.videoWidth > 0) {
                if (!isEngineRunning) startEngine();
            } else {
                // On boucle jusqu'à ce que la vidéo ait des dimensions réelles
                setTimeout(checkReady, 200);
            }
        }

        function startEngine() {
            isEngineRunning = true;
            document.getElementById('aiOverlay').innerText = "RECHERCHE DOCUMENT...";
            
            src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
            dst = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC1);
            cap = new cv.VideoCapture(video);

            // Flash support
            const track = streamRef.getVideoTracks()[0];
            const caps = track.getCapabilities();
            if (caps.torch) document.getElementById('torchBtn').classList.remove('hidden');

            function loop() {
                try {
                    cap.read(src);
                    cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
                    cv.GaussianBlur(dst, dst, new cv.Size(9, 9), 0);
                    cv.Canny(dst, dst, 40, 110);
                    
                    let M = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(5, 5));
                    cv.dilate(dst, dst, M);

                    let contours = new cv.MatVector();
                    let hierarchy = new cv.Mat();
                    cv.findContours(dst, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

                    const canvas = document.getElementById('canvasOutput');
                    const ctx = canvas.getContext('2d');
                    canvas.width = video.clientWidth;
                    canvas.height = video.clientHeight;
                    ctx.clearRect(0, 0, canvas.width, canvas.height);

                    let maxArea = 0;
                    let found = false;

                    for (let i = 0; i < contours.size(); ++i) {
                        let cnt = contours.get(i);
                        let area = cv.contourArea(cnt);
                        if (area > 5000) {
                            let approx = new cv.Mat();
                            cv.approxPolyDP(cnt, approx, 0.03 * cv.arcLength(cnt, true), true);
                            if (approx.rows === 4 && area > maxArea) {
                                maxArea = area;
                                if(lastBestApprox) lastBestApprox.delete();
                                lastBestApprox = approx.clone();
                                found = true;
                                
                                // Dessin du cadre vert
                                ctx.beginPath();
                                ctx.strokeStyle = "#00FF00"; ctx.lineWidth = 6;
                                let pts = approx.data32S;
                                const sx = canvas.width / video.videoWidth;
                                const sy = canvas.height / video.videoHeight;
                                ctx.moveTo(pts[0] * sx, pts[1] * sy);
                                for (let j = 2; j < pts.length; j += 2) ctx.lineTo(pts[j] * sx, pts[j+1] * sy);
                                ctx.closePath(); ctx.stroke();
                            }
                            approx.delete();
                        }
                    }

                    document.getElementById('aiOverlay').innerText = found ? "CADRE DÉTECTÉ ✅" : "CHERCHEZ LES BORDS...";
                    contours.delete(); hierarchy.delete(); M.delete();
                } catch (e) { }
                requestAnimationFrame(loop);
            }
            requestAnimationFrame(loop);
        }

        async function toggleTorch() {
            const track = streamRef.getVideoTracks()[0];
            torchOn = !torchOn;
            await track.applyConstraints({ advanced: [{ torch: torchOn }] });
        }

        function captureAndWarp() {
            if (!lastBestApprox) { alert("Veuillez bien cadrer le document (cadre vert)"); return; }
            
            const w = video.videoWidth;
            const h = video.videoHeight;
            let warpedDst = new cv.Mat(h, w, cv.CV_8UC4);
            let pts1 = cv.matFromArray(4, 1, cv.CV_32FC2, lastBestApprox.data32S);
            let pts2 = cv.matFromArray(4, 1, cv.CV_32FC2, [0, 0, w, 0, w, h, w, h, 0, h]);
            
            // Note: l'ordre des points peut varier selon la détection
            let M = cv.getPerspectiveTransform(pts1, pts2);
            cv.warpPerspective(src, warpedDst, M, new cv.Size(w, h));
            cv.imshow('warpCanvas', warpedDst);
            
            const pdf = new jsPDF({ orientation: w > h ? 'l' : 'p', unit: 'px', format: [w, h] });
            pdf.addImage(document.getElementById('warpCanvas').toDataURL('image/jpeg', 0.9), 'JPEG', 0, 0, w, h);
            
            const name = document.getElementById('docFileName').value || "Scan_" + Date.now();
            pdf.save(name + ".pdf");

            // Sauvegarde Favorites / Historique (Local Storage)
            let history = JSON.parse(localStorage.getItem('doc_scans')) || [];
            history.unshift({ id: Date.now(), name: name, date: new Date().toLocaleDateString() });
            localStorage.setItem('doc_scans', JSON.stringify(history));
            renderHistory();

            warpedDst.delete(); pts1.delete(); pts2.delete(); M.delete();
        }

        function renderHistory() {
            const scans = JSON.parse(localStorage.getItem('doc_scans')) || [];
            document.getElementById('storageHistory').innerHTML = scans.map(s => `
                <div class="bg-slate-800 p-4 rounded-2xl flex justify-between items-center text-xs border-l-4 border-green-500 shadow-lg">
                    <span class="font-bold text-slate-200">${s.name}</span>
                    <span class="text-slate-500">${s.date}</span>
                </div>
            `).join('');
        }

        window.onload = () => { initCamera(); renderHistory(); };
    </script>
</body>
</html>
